#!/usr/bin/env python3
"""
VisionArena-Chatæ•°æ®é›†å¤„ç†å™¨
å¤„ç†æ¥è‡ªHugging Faceçš„VisionArena-Chatæ•°æ®é›†ï¼Œæå–å›¾ç‰‡å’Œå¯¹è¯æ•°æ®
ç”¨äºvLLMå¤šæ¨¡æ€æ¨¡å‹çš„åŸºå‡†æµ‹è¯•

æ•°æ®é›†ä¿¡æ¯:
- 200Kå¯¹è¯
- 45ä¸ªVLMæ¨¡å‹
- 138ç§è¯­è¨€
- ~43Kç‹¬ç‰¹å›¾ç‰‡
- åŒ…å«å„ç§ç±»åˆ«ï¼šCaptioning, OCR, Entity Recognitionç­‰
"""

import os
import sys
import json
import argparse
from pathlib import Path
from io import BytesIO
from typing import List, Dict, Any, Tuple
import logging

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥vllm_metrics_client
sys.path.append(str(Path(__file__).parent.parent))

try:
    from datasets import load_dataset
    from PIL import Image
    import numpy as np
except ImportError as e:
    print(f"âŒ ç¼ºå°‘ä¾èµ–: {e}")
    print("è¯·è¿è¡Œ: uv pip install datasets Pillow")
    sys.exit(1)


class VisionArenaProcessor:
    """VisionArenaæ•°æ®é›†å¤„ç†å™¨"""
    
    def __init__(self, output_dir: str = "benchmark_datasets/vision_arena"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        self.images_dir = self.output_dir / "images"
        self.conversations_dir = self.output_dir / "conversations"
        self.images_dir.mkdir(exist_ok=True)
        self.conversations_dir.mkdir(exist_ok=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_samples': 0,
            'processed_samples': 0,
            'saved_images': 0,
            'failed_images': 0,
            'categories': {},
            'languages': {},
            'models': {}
        }
    
    def load_dataset_sample(self, num_samples: int = 1000, streaming: bool = False) -> Any:
        """
        åŠ è½½VisionArenaæ•°æ®é›†
        
        Args:
            num_samples: è¦å¤„ç†çš„æ ·æœ¬æ•°é‡ï¼ˆNoneè¡¨ç¤ºå…¨éƒ¨ï¼‰
            streaming: æ˜¯å¦ä½¿ç”¨æµå¼åŠ è½½ï¼ˆé€‚åˆå¤§æ•°æ®é›†ï¼‰
        """
        print(f"ğŸ“‚ åŠ è½½VisionArena-Chatæ•°æ®é›†...")
        print(f"   æ ·æœ¬æ•°é‡: {num_samples if num_samples else 'å…¨éƒ¨'}")
        print(f"   æµå¼åŠ è½½: {streaming}")
        
        try:
            if streaming:
                dataset = load_dataset(
                    "lmarena-ai/VisionArena-Chat", 
                    streaming=True,
                    split="train"
                )
                if num_samples:
                    dataset = dataset.take(num_samples)
            else:
                dataset = load_dataset(
                    "lmarena-ai/VisionArena-Chat",
                    split=f"train[:{num_samples}]" if num_samples else "train"
                )
                
            return dataset
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ•°æ®é›†å¤±è´¥: {e}")
            return None
    
    def extract_image_from_sample(self, sample: Dict[str, Any], sample_id: str) -> Tuple[str, bool]:
        """
        ä»æ ·æœ¬ä¸­æå–å¹¶ä¿å­˜å›¾ç‰‡
        
        Args:
            sample: æ•°æ®é›†æ ·æœ¬
            sample_id: æ ·æœ¬ID
            
        Returns:
            (å›¾ç‰‡è·¯å¾„, æ˜¯å¦æˆåŠŸ)
        """
        try:
            images = sample.get('images', [])
            if not images:
                return "", False
            
            # å–ç¬¬ä¸€å¼ å›¾ç‰‡
            image_data = images[0]
            
            # è§£ç å›¾ç‰‡
            if isinstance(image_data, dict) and 'bytes' in image_data:
                image_bytes = image_data['bytes']
                image = Image.open(BytesIO(image_bytes))
            else:
                # å¦‚æœæ˜¯å…¶ä»–æ ¼å¼ï¼Œå°è¯•ç›´æ¥æ‰“å¼€
                image = image_data
            
            # ä¿å­˜å›¾ç‰‡
            image_filename = f"image_{sample_id}.jpg"
            image_path = self.images_dir / image_filename
            
            # è½¬æ¢ä¸ºRGBï¼ˆå¦‚æœéœ€è¦ï¼‰
            if image.mode != 'RGB':
                image = image.convert('RGB')
            
            image.save(image_path, 'JPEG', quality=85)
            self.stats['saved_images'] += 1
            
            return str(image_path), True
            
        except Exception as e:
            print(f"âš ï¸  å›¾ç‰‡æå–å¤±è´¥ (æ ·æœ¬ {sample_id}): {e}")
            self.stats['failed_images'] += 1
            return "", False
    
    def process_conversation(self, sample: Dict[str, Any]) -> Dict[str, Any]:
        """
        å¤„ç†å¯¹è¯æ•°æ®ï¼Œè½¬æ¢ä¸ºvLLMæµ‹è¯•æ ¼å¼
        
        Args:
            sample: åŸå§‹æ ·æœ¬æ•°æ®
            
        Returns:
            å¤„ç†åçš„å¯¹è¯æ•°æ®
        """
        conversation = sample.get('conversation', [])
        
        # æå–ç¬¬ä¸€è½®å¯¹è¯ï¼ˆç”¨æˆ·é—®é¢˜ï¼‰
        user_message = ""
        assistant_message = ""
        
        # conversationæ˜¯åµŒå¥—åˆ—è¡¨ç»“æ„: [[{user}], [{assistant}]]
        for turn_group in conversation:
            if isinstance(turn_group, list):
                for turn in turn_group:
                    if isinstance(turn, dict):
                        role = turn.get('role', '')
                        content = turn.get('content', '')
                        
                        if role == 'user' and not user_message:
                            user_message = content
                        elif role == 'assistant' and not assistant_message:
                            assistant_message = content
                            break
            elif isinstance(turn_group, dict):
                # å¦‚æœç›´æ¥æ˜¯å­—å…¸æ ¼å¼
                role = turn_group.get('role', '')
                content = turn_group.get('content', '')
                
                if role == 'user' and not user_message:
                    user_message = content
                elif role == 'assistant' and not assistant_message:
                    assistant_message = content
                    break
        
        # ç»Ÿè®¡ç±»åˆ«
        categories = sample.get('categories', {})
        for category, is_present in categories.items():
            if is_present:
                self.stats['categories'][category] = self.stats['categories'].get(category, 0) + 1
        
        # ç»Ÿè®¡è¯­è¨€å’Œæ¨¡å‹
        language = sample.get('language', 'unknown')
        model = sample.get('model', 'unknown')
        self.stats['languages'][language] = self.stats['languages'].get(language, 0) + 1
        self.stats['models'][model] = self.stats['models'].get(model, 0) + 1
        
        return {
            'user_message': user_message,
            'assistant_message': assistant_message,
            'categories': categories,
            'language': language,
            'model': model,
            'num_turns': sample.get('num_turns', 1),
            'conversation_id': sample.get('conversation_id', ''),
            'timestamp': sample.get('tstamp', 0)
        }
    
    def create_vllm_test_format(self, image_path: str, conversation: Dict[str, Any]) -> Dict[str, Any]:
        """
        åˆ›å»ºé€‚åˆvLLMæµ‹è¯•çš„æ ¼å¼
        
        Args:
            image_path: å›¾ç‰‡è·¯å¾„
            conversation: å¯¹è¯æ•°æ®
            
        Returns:
            vLLMæµ‹è¯•æ ¼å¼çš„æ•°æ®
        """
        return {
            'image_path': image_path,
            'prompt': conversation['user_message'],
            'expected_response': conversation['assistant_message'],
            'metadata': {
                'categories': conversation['categories'],
                'language': conversation['language'],
                'original_model': conversation['model'],
                'num_turns': conversation['num_turns'],
                'conversation_id': conversation['conversation_id']
            }
        }
    
    def process_dataset(self, num_samples: int = 1000, streaming: bool = True) -> List[Dict[str, Any]]:
        """
        å¤„ç†æ•´ä¸ªæ•°æ®é›†
        
        Args:
            num_samples: å¤„ç†çš„æ ·æœ¬æ•°é‡
            streaming: æ˜¯å¦ä½¿ç”¨æµå¼å¤„ç†
            
        Returns:
            å¤„ç†åçš„æµ‹è¯•æ•°æ®åˆ—è¡¨
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç†VisionArenaæ•°æ®é›†...")
        
        # åŠ è½½æ•°æ®é›†
        dataset = self.load_dataset_sample(num_samples, streaming)
        if dataset is None:
            return []
        
        processed_data = []
        
        try:
            # å¤„ç†æ ·æœ¬
            for i, sample in enumerate(dataset):
                self.stats['total_samples'] += 1
                
                # ç”Ÿæˆæ ·æœ¬ID
                sample_id = f"{i:06d}"
                
                # æå–å›¾ç‰‡
                image_path, image_success = self.extract_image_from_sample(sample, sample_id)
                
                if not image_success:
                    continue
                
                # å¤„ç†å¯¹è¯
                conversation = self.process_conversation(sample)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ç”¨æˆ·æ¶ˆæ¯
                if not conversation['user_message'].strip():
                    continue
                
                # åˆ›å»ºæµ‹è¯•æ ¼å¼
                test_item = self.create_vllm_test_format(image_path, conversation)
                processed_data.append(test_item)
                
                self.stats['processed_samples'] += 1
                
                # è¿›åº¦æ˜¾ç¤º
                if (i + 1) % 100 == 0:
                    print(f"   å¤„ç†è¿›åº¦: {i+1}/{num_samples if num_samples else '?'} "
                          f"(æˆåŠŸ: {self.stats['processed_samples']}, "
                          f"å›¾ç‰‡: {self.stats['saved_images']})")
                
                # å¦‚æœä¸æ˜¯æµå¼ä¸”è¾¾åˆ°äº†æŒ‡å®šæ•°é‡ï¼Œè·³å‡º
                if not streaming and num_samples and len(processed_data) >= num_samples:
                    break
                    
        except Exception as e:
            print(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        
        return processed_data
    
    def save_processed_data(self, data: List[Dict[str, Any]], filename: str = "vision_arena_test_data.json"):
        """ä¿å­˜å¤„ç†åçš„æ•°æ®"""
        output_file = self.output_dir / filename
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜: {output_file}")
        print(f"   å¤„ç†çš„æ ·æœ¬: {len(data)}")
        
        return str(output_file)
    
    def print_statistics(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡:")
        print(f"   æ€»æ ·æœ¬æ•°: {self.stats['total_samples']}")
        print(f"   æˆåŠŸå¤„ç†: {self.stats['processed_samples']}")
        print(f"   ä¿å­˜å›¾ç‰‡: {self.stats['saved_images']}")
        print(f"   å¤±è´¥å›¾ç‰‡: {self.stats['failed_images']}")
        
        print(f"\nğŸ·ï¸  ç±»åˆ«åˆ†å¸ƒ (å‰10):")
        sorted_categories = sorted(self.stats['categories'].items(), key=lambda x: x[1], reverse=True)
        for category, count in sorted_categories[:10]:
            print(f"   {category}: {count}")
        
        print(f"\nğŸŒ è¯­è¨€åˆ†å¸ƒ (å‰10):")
        sorted_languages = sorted(self.stats['languages'].items(), key=lambda x: x[1], reverse=True)
        for language, count in sorted_languages[:10]:
            print(f"   {language}: {count}")
        
        print(f"\nğŸ¤– æ¨¡å‹åˆ†å¸ƒ (å‰10):")
        sorted_models = sorted(self.stats['models'].items(), key=lambda x: x[1], reverse=True)
        for model, count in sorted_models[:10]:
            print(f"   {model}: {count}")


def main():
    parser = argparse.ArgumentParser(description="å¤„ç†VisionArena-Chatæ•°æ®é›†")
    parser.add_argument("--num_samples", type=int, default=1000,
                       help="è¦å¤„ç†çš„æ ·æœ¬æ•°é‡ (é»˜è®¤: 1000)")
    parser.add_argument("--output_dir", type=str, default="benchmark_datasets/vision_arena",
                       help="è¾“å‡ºç›®å½• (é»˜è®¤: benchmark_datasets/vision_arena)")
    parser.add_argument("--streaming", action="store_true",
                       help="ä½¿ç”¨æµå¼åŠ è½½ (é€‚åˆå¤§æ•°æ®é›†)")
    parser.add_argument("--output_file", type=str, default="vision_arena_test_data.json",
                       help="è¾“å‡ºæ–‡ä»¶å (é»˜è®¤: vision_arena_test_data.json)")
    
    args = parser.parse_args()
    
    print("ğŸ” VisionArena-Chatæ•°æ®é›†å¤„ç†å™¨")
    print("=" * 50)
    print(f"æ•°æ®é›†æ¥æº: https://huggingface.co/datasets/lmarena-ai/VisionArena-Chat")
    print(f"æ ·æœ¬æ•°é‡: {args.num_samples}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"æµå¼å¤„ç†: {args.streaming}")
    
    # åˆ›å»ºå¤„ç†å™¨
    processor = VisionArenaProcessor(args.output_dir)
    
    # å¤„ç†æ•°æ®é›†
    processed_data = processor.process_dataset(
        num_samples=args.num_samples,
        streaming=args.streaming
    )
    
    if processed_data:
        # ä¿å­˜æ•°æ®
        output_file = processor.save_processed_data(processed_data, args.output_file)
        
        # æ‰“å°ç»Ÿè®¡
        processor.print_statistics()
        
        print(f"\nâœ… å¤„ç†å®Œæˆ!")
        print(f"   ğŸ“ å›¾ç‰‡ç›®å½•: {processor.images_dir}")
        print(f"   ğŸ“„ æ•°æ®æ–‡ä»¶: {output_file}")
        print(f"   ğŸ¯ å¯ç”¨äºvLLMå¤šæ¨¡æ€æ¨¡å‹æµ‹è¯•")
        
    else:
        print("âŒ æœªèƒ½å¤„ç†ä»»ä½•æ•°æ®")


if __name__ == "__main__":
    main()
