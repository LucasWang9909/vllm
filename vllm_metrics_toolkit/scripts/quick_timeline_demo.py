#!/usr/bin/env python3
"""
å¿«é€Ÿæ—¶é—´çº¿å¯è§†åŒ–æ¼”ç¤º
ç®€å•æ˜“ç”¨çš„æ¥å£æ¥ç”Ÿæˆè¯·æ±‚æ—¶é—´çº¿å›¾è¡¨
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from request_timeline_visualizer import RequestTimelineVisualizer
import json
import matplotlib
matplotlib.use('Agg')  # æ— GUIåç«¯
import matplotlib.pyplot as plt


def quick_demo(json_file):
    """å¿«é€Ÿæ¼”ç¤ºåŠŸèƒ½"""
    print(f"ğŸš€ Quick Timeline Visualization Demo")
    print(f"ğŸ“‚ Input file: {json_file}")
    
    # åŠ è½½æ•°æ®
    try:
        with open(json_file, 'r') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ Error loading file: {e}")
        return
    
    # åˆ›å»ºå¯è§†åŒ–å™¨
    visualizer = RequestTimelineVisualizer(data)
    
    if not visualizer.timelines:
        print("âŒ No timeline data found")
        return
    
    print(f"âœ… Found {len(visualizer.timelines)} valid requests")
    
    # 1. åˆ›å»ºæ¦‚è§ˆç”˜ç‰¹å›¾ï¼ˆå‰20ä¸ªè¯·æ±‚ï¼‰
    print("ğŸ“Š Creating overview Gantt chart...")
    fig1 = visualizer.create_gantt_chart(max_requests=20, figsize=(14, 10))
    if fig1:
        fig1.savefig('overview_timeline.png', dpi=300, bbox_inches='tight')
        plt.close(fig1)
        print("ğŸ’¾ Overview saved: overview_timeline.png")
    
    # 2. åˆ›å»ºè¯¦ç»†è§†å›¾ï¼ˆå‰5ä¸ªè¯·æ±‚çš„ITLç»†èŠ‚ï¼‰
    print("ğŸ“Š Creating detailed ITL view...")
    fig2 = visualizer.create_detailed_request_view(
        request_indices=[0, 1, 2, 3, 4], 
        figsize=(14, 8)
    )
    if fig2:
        fig2.savefig('detailed_itl_view.png', dpi=300, bbox_inches='tight')
        plt.close(fig2)
        print("ğŸ’¾ Detailed view saved: detailed_itl_view.png")
    
    # 3. ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
    stats = visualizer.generate_statistics_report()
    
    print(f"\nğŸ“ˆ Performance Summary:")
    print(f"   ğŸ”„ Total Requests: {stats.get('total_requests', 0)}")
    print(f"   âš¡ Max Concurrent: {stats.get('concurrency_stats', {}).get('max_concurrent', 0)}")
    print(f"   ğŸ“Š Avg Concurrent: {stats.get('concurrency_stats', {}).get('avg_concurrent', 0):.1f}")
    print(f"   â±ï¸  Avg Queue Time: {stats.get('queue_time_stats', {}).get('mean', 0):.1f}ms")
    print(f"   ğŸ§  Avg Prefill Time: {stats.get('prefill_time_stats', {}).get('mean', 0):.1f}ms")
    print(f"   â²ï¸  Avg Total Duration: {stats.get('duration_stats', {}).get('mean', 0):.1f}s")
    
    # 4. æ˜¾ç¤ºå¹¶å‘åˆ†ææ´å¯Ÿ
    concurrency = stats.get('concurrency_stats', {})
    max_concurrent = concurrency.get('max_concurrent', 0)
    avg_concurrent = concurrency.get('avg_concurrent', 0)
    
    print(f"\nğŸ¯ Key Insights:")
    if max_concurrent > 200:
        print(f"   ğŸ”¥ High concurrency detected! Peak: {max_concurrent} requests")
        print(f"   ğŸ’¡ Your async RPS control is working well")
    
    queue_avg = stats.get('queue_time_stats', {}).get('mean', 0)
    if queue_avg > 100:
        print(f"   âš ï¸  Significant queue time detected: {queue_avg:.1f}ms average")
        print(f"   ğŸ’¡ Consider optimizing request scheduling or increasing capacity")
    else:
        print(f"   âœ… Low queue times: {queue_avg:.1f}ms average - good performance!")
    
    efficiency = avg_concurrent / max_concurrent if max_concurrent > 0 else 0
    print(f"   ğŸ“ˆ Concurrency efficiency: {efficiency:.1%} (avg/max concurrent)")
    
    print(f"\nğŸ¨ Generated Visualizations:")
    print(f"   ğŸ“Š overview_timeline.png - Shows request lifecycle stages")
    print(f"   ğŸ” detailed_itl_view.png - Shows individual token latencies")
    print(f"   ğŸ’¡ Use these to understand your system's performance patterns!")


def main():
    if len(sys.argv) != 2:
        print("Usage: python quick_timeline_demo.py <benchmark_json_file>")
        print("Example: python quick_timeline_demo.py my_test_20250922_165706.json.json")
        return
    
    json_file = sys.argv[1]
    if not os.path.exists(json_file):
        print(f"âŒ File not found: {json_file}")
        return
    
    quick_demo(json_file)


if __name__ == "__main__":
    main()
