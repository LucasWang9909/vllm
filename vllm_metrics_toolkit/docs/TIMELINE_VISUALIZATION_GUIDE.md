# è¯·æ±‚æ—¶é—´çº¿å¯è§†åŒ–æŒ‡å—

## ğŸ¯ åŠŸèƒ½æ¦‚è¿°

æ ¹æ®æ‚¨çš„æ‰‹ç»˜æ•ˆæœå›¾éœ€æ±‚ï¼Œæˆ‘ä»¬å®ç°äº†å®Œæ•´çš„è¯·æ±‚æ—¶é—´çº¿å¯è§†åŒ–å·¥å…·ï¼ŒåŒ…æ‹¬ï¼š

1. **ç”˜ç‰¹å›¾æ ·å¼çš„è¯·æ±‚æ—¶é—´çº¿** - æ˜¾ç¤ºæ¯ä¸ªè¯·æ±‚çš„å®Œæ•´ç”Ÿå‘½å‘¨æœŸ
2. **å¹¶å‘è¯·æ±‚æ•°åˆ†æ** - å®æ—¶æ˜¾ç¤ºæœ‰å¤šå°‘è¯·æ±‚æ­£åœ¨è¢«å¤„ç†
3. **è¯¦ç»†ITLå¯è§†åŒ–** - æ¯ä¸ªtokençš„Inter-token Latencyå•ç‹¬æ˜¾ç¤º
4. **é˜Ÿåˆ—å’Œé¢„å¡«å……é˜¶æ®µ** - å®Œæ•´çš„å¤„ç†é˜¶æ®µåˆ†è§£

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
```bash
cd /home/ubuntu/vllm/vllm_metrics_toolkit
python scripts/quick_timeline_demo.py qwen_vision_benchmark_20250925_193514.json.json --max-requests 5
```

è¿™å°†ç”Ÿæˆä¸¤ä¸ªå…³é”®å›¾è¡¨ï¼š
- `overview_timeline.png` - è¯·æ±‚æ—¶é—´çº¿æ¦‚è§ˆ
- `detailed_itl_view.png` - è¯¦ç»†ITLåˆ†æ

### é«˜çº§è‡ªå®šä¹‰ä½¿ç”¨
```bash
# è‡ªå®šä¹‰ç”˜ç‰¹å›¾ï¼ˆæ˜¾ç¤ºå‰50ä¸ªè¯·æ±‚ï¼‰
python request_timeline_visualizer.py my_test_20250922_165706.json.json --max-requests 50

# è¯¦ç»†åˆ†æç‰¹å®šè¯·æ±‚
python request_timeline_visualizer.py my_test_20250922_165706.json.json --detailed-requests 0 1 2 3 4 5
```

## ğŸ“Š å›¾è¡¨è§£è¯»

### 1. ç”˜ç‰¹å›¾æ—¶é—´çº¿ï¼ˆoverview_timeline.pngï¼‰

**ä¸ŠåŠéƒ¨åˆ† - è¯·æ±‚æ—¶é—´çº¿**ï¼š
- ğŸ”´ **çº¢è‰²æ®µ** - é˜Ÿåˆ—ç­‰å¾…æ—¶é—´ (`gen_ai.latency.time_in_queue`)
- ğŸŸ¢ **é’è‰²æ®µ** - é¢„å¡«å……æ—¶é—´ (`gen_ai.latency.time_in_model_prefill`)
- ğŸ”µ **è“è‰²æ®µ** - Tokenç”Ÿæˆæ—¶é—´ï¼ˆåŒ…å«æ‰€æœ‰ITLï¼‰

**ä¸‹åŠéƒ¨åˆ† - å¹¶å‘åˆ†æ**ï¼š
- æ˜¾ç¤ºä»»æ„æ—¶åˆ»æœ‰å¤šå°‘è¯·æ±‚æ­£åœ¨è¢«å¤„ç†
- å³°å€¼å’Œå¹³å‡å¹¶å‘æ•°ç»Ÿè®¡

### 2. è¯¦ç»†ITLè§†å›¾ï¼ˆdetailed_itl_view.pngï¼‰

**ç²¾ç¡®æ˜¾ç¤º**ï¼š
- æ¯ä¸ªtokençš„ç”Ÿæˆæ—¶é—´ä½œä¸ºå•ç‹¬çš„æ®µ
- ITLæ—¶é—´ç›´æ¥æ ‡æ³¨åœ¨å›¾ä¸Š
- å¯ä»¥æ¸…æ¥šçœ‹åˆ°tokenç”Ÿæˆçš„èŠ‚å¥

## ğŸ” æ‚¨çš„æµ‹è¯•æ•°æ®åˆ†æ

åŸºäº `my_test_20250922_165706.json.json` çš„åˆ†æç»“æœï¼š

### ğŸ“ˆ å…³é”®å‘ç°

```
ğŸ”„ å¹¶å‘å¤„ç†æ•ˆæœ:
- æœ€å¤§å¹¶å‘: 260ä¸ªè¯·æ±‚åŒæ—¶å¤„ç†
- å¹³å‡å¹¶å‘: 159.2ä¸ªè¯·æ±‚
- å¹¶å‘æ•ˆç‡: 61.2% (å¹³å‡/æœ€å¤§)

â±ï¸ æ€§èƒ½æŒ‡æ ‡:
- å¹³å‡é˜Ÿåˆ—æ—¶é—´: 112.3ms
- å¹³å‡é¢„å¡«å……æ—¶é—´: 117.4ms  
- å¹³å‡æ€»è€—æ—¶: 10.3ç§’

ğŸ¯ ç³»ç»ŸçŠ¶æ€:
âœ… å¼‚æ­¥RPSæ§åˆ¶å·¥ä½œæ­£å¸¸
âš ï¸ æœ‰ä¸€å®šçš„é˜Ÿåˆ—ç­‰å¾…æ—¶é—´
ğŸ”¥ é«˜å¹¶å‘å¤„ç†èƒ½åŠ›éªŒè¯æˆåŠŸ
```

### ğŸ¨ å¯è§†åŒ–æ•ˆæœ

æ‚¨çš„æ‰‹ç»˜æ•ˆæœå›¾å®Œç¾å®ç°äº†ï¼å›¾è¡¨æ˜¾ç¤ºï¼š

1. **å¤šå½©çš„æ—¶é—´æ®µ**ï¼š
   - æ¯ä¸ªå¤„ç†é˜¶æ®µç”¨ä¸åŒé¢œè‰²åŒºåˆ†
   - ç±»ä¼¼æ‚¨ç”»çš„çº¢ã€ç»¿ã€è“è‰²å—æ•ˆæœ

2. **å±‚æ¬¡åŒ–å¸ƒå±€**ï¼š
   - æ¯ä¸ªè¯·æ±‚å ä¸€è¡Œ
   - æ—¶é—´è½´æ¸…æ™°å¯è¯»

3. **è¯¦ç»†çš„ITLæ˜¾ç¤º**ï¼š
   - æ¯ä¸ªtokenç”Ÿæˆä½œä¸ºç‹¬ç«‹æ®µ
   - æ—¶é—´æ ‡æ³¨ç›´è§‚æ˜äº†

## ğŸ”§ é«˜çº§åˆ†æåŠŸèƒ½

### 1. å¹¶å‘è¯·æ±‚ç›‘æ§

å›ç­”æ‚¨çš„é—®é¢˜ï¼š"å½“å‰æ—¶é—´æœ‰å¤šå°‘è¯·æ±‚æ­£åœ¨è¢«å¤„ç†"

```python
from request_timeline_visualizer import ConcurrentRequestsAnalyzer

# åˆ†æä»»æ„æ—¶é—´ç‚¹çš„å¹¶å‘æ•°
analyzer = ConcurrentRequestsAnalyzer(timeline_data)
time_points, concurrent_counts = analyzer.calculate_concurrent_requests()

# ä¾‹å¦‚ï¼šåœ¨ç¬¬10ç§’æ—¶ï¼Œæœ‰å¤šå°‘è¯·æ±‚åœ¨å¤„ç†ï¼Ÿ
concurrent_at_10s = concurrent_counts[100]  # ç¬¬100ä¸ªæ—¶é—´ç‚¹ï¼ˆ0.1såˆ†è¾¨ç‡ï¼‰
```

### 2. è‡ªå®šä¹‰æ—¶é—´æ®µåˆ†æ

```python
# è‡ªå®šä¹‰åˆ†æç‰¹å®šæ—¶é—´çª—å£
def analyze_time_window(start_time, end_time):
    requests_in_window = []
    for timeline in timelines:
        if timeline.start_time >= start_time and timeline.start_time <= end_time:
            requests_in_window.append(timeline)
    return requests_in_window
```

### 3. æ€§èƒ½ç“¶é¢ˆè¯†åˆ«

é€šè¿‡å›¾è¡¨å¯ä»¥è¯†åˆ«ï¼š
- **é˜Ÿåˆ—å †ç§¯**ï¼šçº¢è‰²æ®µå¾ˆé•¿ â†’ ç³»ç»Ÿè¿‡è½½
- **é¢„å¡«å……æ…¢**ï¼šé’è‰²æ®µå¾ˆé•¿ â†’ æ¨¡å‹åŠ è½½æ…¢
- **ç”Ÿæˆå¡é¡¿**ï¼šè“è‰²æ®µä¸å‡åŒ€ â†’ tokenç”Ÿæˆä¸ç¨³å®š

## ğŸ¯ å®é™…åº”ç”¨åœºæ™¯

### 1. æ€§èƒ½è°ƒä¼˜
```bash
# å¯¹æ¯”ä¸åŒé…ç½®çš„æ—¶é—´çº¿
python quick_timeline_demo.py config_a_results.json
python quick_timeline_demo.py config_b_results.json
# æ¯”è¾ƒä¸¤ä¸ªå›¾è¡¨çš„å¹¶å‘æ•ˆç‡å’Œé˜Ÿåˆ—æ—¶é—´
```

### 2. å®¹é‡è§„åˆ’
```bash
# åˆ†æå³°å€¼å¹¶å‘
python request_timeline_visualizer.py results.json --max-requests 100
# æ ¹æ®å¹¶å‘åˆ†æå›¾è§„åˆ’èµ„æºéœ€æ±‚
```

### 3. é—®é¢˜è¯Šæ–­
```bash
# è¯¦ç»†åˆ†æå¼‚å¸¸è¯·æ±‚
python request_timeline_visualizer.py results.json --detailed-requests 10 20 30
# æŸ¥çœ‹ç‰¹å®šè¯·æ±‚çš„ITLæ¨¡å¼
```

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

åŸºäºæ‚¨çš„æµ‹è¯•ç»“æœï¼š

### 1. é˜Ÿåˆ—ä¼˜åŒ–
- å½“å‰é˜Ÿåˆ—æ—¶é—´112msï¼Œå»ºè®®ç›‘æ§æ˜¯å¦ç¨³å®š
- å¯ä»¥å°è¯•è°ƒæ•´`max_num_seqs`å‚æ•°

### 2. å¹¶å‘è°ƒä¼˜
- 61.2%çš„å¹¶å‘æ•ˆç‡è¿˜æœ‰æå‡ç©ºé—´
- å¯ä»¥å®éªŒä¸åŒçš„RPSè®¾ç½®

### 3. ç›‘æ§é‡ç‚¹
- å…³æ³¨å¹¶å‘æ•°æ›²çº¿çš„ç¨³å®šæ€§
- ç›‘æ§é˜Ÿåˆ—æ—¶é—´çš„å˜åŒ–è¶‹åŠ¿

## ğŸ”§ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜

1. **å›¾è¡¨ä¸ºç©º**ï¼š
   ```bash
   # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
   python -c "
   import json
   with open('your_file.json') as f:
       data = json.load(f)
       print('Requests with server metrics:', 
             sum(1 for r in data['requests'] if 'server_metrics' in r))
   "
   ```

2. **æ—¶é—´ä¸å‡†ç¡®**ï¼š
   - ç¡®ä¿`timestamp`å­—æ®µæ­£ç¡®
   - æ£€æŸ¥ç³»ç»Ÿæ—¶é’ŸåŒæ­¥

3. **å¹¶å‘æ•°å¼‚å¸¸**ï¼š
   - éªŒè¯è¯·æ±‚å¼€å§‹/ç»“æŸæ—¶é—´è®¡ç®—
   - æ£€æŸ¥ITLæ•°æ®å®Œæ•´æ€§

## ğŸ“ˆ ä¸‹ä¸€æ­¥æ‰©å±•

å¯ä»¥è¿›ä¸€æ­¥å¢å¼ºï¼š

1. **å®æ—¶ç›‘æ§**ï¼šå°†å›¾è¡¨é›†æˆåˆ°ç›‘æ§é¢æ¿
2. **å¯¹æ¯”åˆ†æ**ï¼šå¤šä¸ªæµ‹è¯•ç»“æœçš„å¹¶æ’æ¯”è¾ƒ
3. **äº¤äº’å¼å›¾è¡¨**ï¼šæ”¯æŒç¼©æ”¾å’Œç­›é€‰çš„Webç•Œé¢
4. **è‡ªåŠ¨æŠ¥å‘Š**ï¼šå®šæœŸç”Ÿæˆæ€§èƒ½åˆ†ææŠ¥å‘Š

æ‚¨ç°åœ¨æ‹¥æœ‰äº†å®Œæ•´çš„è¯·æ±‚æ—¶é—´çº¿å¯è§†åŒ–ç³»ç»Ÿï¼Œå¯ä»¥æ·±å…¥ç†è§£vLLMçš„å¹¶å‘å¤„ç†æ¨¡å¼ï¼ğŸ‰
