# ShareGPTåŸºå‡†æµ‹è¯•ä½¿ç”¨æŒ‡å—

è¿™ä¸ªå·¥å…·åŒ…ç°åœ¨åŒ…å«äº†ä¸“é—¨çš„ShareGPTåŸºå‡†æµ‹è¯•åŠŸèƒ½ï¼Œå¯ä»¥ä½¿ç”¨å‰1000ä¸ªå¯¹è¯æç¤ºè¿›è¡Œæ€§èƒ½æµ‹è¯•ã€‚

## ğŸ“‹ å‰ææ¡ä»¶

### 1. å¯åŠ¨vLLMæœåŠ¡
```bash
# å¯åŠ¨æ”¯æŒOpenTelemetryçš„vLLMæœåŠ¡
vllm serve <your-model> \
  --otlp-traces-endpoint http://localhost:4317 \
  --collect-detailed-traces all \
  --port 8000
```

### 2. å¯åŠ¨Jaegerè¿½è¸ªæœåŠ¡
```bash
# ä½¿ç”¨Dockerå¯åŠ¨Jaeger
docker run --rm --name jaeger \
  -p 16686:16686 -p 14250:14250 -p 4317:4317 -p 4318:4318 \
  jaegertracing/all-in-one:latest
```

### 3. æ¿€æ´»Pythonç¯å¢ƒ
```bash
cd /home/ubuntu/vllm
source .venv/bin/activate
```

## ğŸš€ è¿è¡ŒåŸºå‡†æµ‹è¯•

### æ–¹æ³•1: ä½¿ç”¨äº¤äº’å¼è„šæœ¬ (æ¨è)
```bash
cd /home/ubuntu/vllm/vllm_metrics_toolkit
python run_benchmark_example.py
```

è¿™ä¼šç»™ä½ é€‰æ‹©ï¼š
- **å¿«é€Ÿæµ‹è¯•**: 10ä¸ªæç¤ºï¼Œ2 RPSï¼ˆçº¦5ç§’å®Œæˆï¼‰
- **å®Œæ•´åŸºå‡†æµ‹è¯•**: 1000ä¸ªæç¤ºï¼Œ1 RPSï¼ˆçº¦17åˆ†é’Ÿå®Œæˆï¼‰

### æ–¹æ³•2: ç›´æ¥ä½¿ç”¨å‘½ä»¤è¡Œ
```bash
cd /home/ubuntu/vllm/vllm_metrics_toolkit

# å¿«é€Ÿæµ‹è¯• - 10ä¸ªæç¤º
python benchmark_sharegpt.py --rps 2 --num_prompts 10 --max_tokens 50

# å®Œæ•´åŸºå‡†æµ‹è¯• - 1000ä¸ªæç¤ºï¼Œ1 RPS
python benchmark_sharegpt.py --rps 1 --num_prompts 1000

# è‡ªå®šä¹‰é…ç½®
python benchmark_sharegpt.py \
  --rps 1.5 \
  --num_prompts 500 \
  --temperature 0.8 \
  --max_tokens 200 \
  --output_prefix "my_test"
```

## ğŸ“Š è¾“å‡ºç»“æœ

### æ§åˆ¶å°è¾“å‡º
æµ‹è¯•è¿‡ç¨‹ä¸­ä¼šæ˜¾ç¤ºï¼š
- è¿›åº¦æ›´æ–°ï¼ˆæ¯50ä¸ªè¯·æ±‚ï¼‰
- å®æ—¶ç»Ÿè®¡
- æœ€ç»ˆåŸºå‡†æµ‹è¯•æ‘˜è¦

### ä¿å­˜çš„æ–‡ä»¶
æµ‹è¯•å®Œæˆåä¼šè‡ªåŠ¨ä¿å­˜ï¼š
- `{timestamp}_results.json` - å®Œæ•´çš„è¯¦ç»†æ•°æ®
- `{timestamp}_results.csv` - ä¾¿äºåˆ†æçš„CSVæ ¼å¼

### å…³é”®æŒ‡æ ‡
- **TTFT** (Time to First Token): é¦–æ¬¡tokenç”Ÿæˆæ—¶é—´
- **TPOT** (Time per Output Token): æ¯tokenå¹³å‡ç”Ÿæˆæ—¶é—´
- **ITL** (Inter-token Latency): tokené—´å»¶è¿Ÿ
- **é˜Ÿåˆ—æ—¶é—´**: æœåŠ¡ç«¯é˜Ÿåˆ—ç­‰å¾…æ—¶é—´
- **ç«¯åˆ°ç«¯å»¶è¿Ÿ**: å®Œæ•´è¯·æ±‚å“åº”æ—¶é—´

## ğŸ›ï¸ å‚æ•°è¯´æ˜

| å‚æ•° | é»˜è®¤å€¼ | è¯´æ˜ |
|------|--------|------|
| `--rps` | 1.0 | æ¯ç§’è¯·æ±‚æ•°ã€‚è®¾ä¸º0åˆ™æ— é™åˆ¶å¹¶å‘ |
| `--num_prompts` | 1000 | è¦æµ‹è¯•çš„æç¤ºæ•°é‡ |
| `--temperature` | 0.7 | æ¨¡å‹æ¸©åº¦å‚æ•° |
| `--max_tokens` | 150 | æœ€å¤§ç”Ÿæˆtokenæ•° |
| `--vllm_url` | http://localhost:8000 | vLLMæœåŠ¡URL |
| `--jaeger_url` | http://localhost:16686 | Jaeger UI URL |
| `--output_prefix` | sharegpt_benchmark | è¾“å‡ºæ–‡ä»¶å‰ç¼€ |

## ğŸ” æ•°æ®é›†ä¿¡æ¯

- **æ•°æ®é›†**: ShareGPT_V3_unfiltered_cleaned_split.json
- **æ€»æ¡ç›®æ•°**: 94,145ä¸ªå¯¹è¯
- **æµ‹è¯•èŒƒå›´**: å‰1000ä¸ªhumanæç¤º
- **æç¤ºæ¥æº**: æ¯ä¸ªå¯¹è¯ä¸­çš„ç¬¬ä¸€ä¸ªhumanæ¶ˆæ¯

## ğŸ“ˆ ç»“æœåˆ†æ

### æŸ¥çœ‹Jaegerè¿½è¸ª
1. æ‰“å¼€ http://localhost:16686
2. æœç´¢æœåŠ¡å: `vllm`
3. æŸ¥çœ‹è¯¦ç»†çš„è¯·æ±‚è¿½è¸ªä¿¡æ¯

### CSVæ•°æ®åˆ†æ
å¯ä»¥ä½¿ç”¨Excelã€Python pandasç­‰å·¥å…·åˆ†æCSVç»“æœï¼š
```python
import pandas as pd
df = pd.read_csv('your_results.csv')
print(df.describe())  # ç»Ÿè®¡æ‘˜è¦
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **æµ‹è¯•æ—¶é—´**: 1000ä¸ªæç¤º@1RPSå¤§çº¦éœ€è¦17åˆ†é’Ÿ
2. **èµ„æºä½¿ç”¨**: ç¡®ä¿vLLMæœåŠ¡æœ‰è¶³å¤Ÿçš„GPUå†…å­˜
3. **ç½‘ç»œè¿æ¥**: ç¡®ä¿å®¢æˆ·ç«¯åˆ°vLLMæœåŠ¡çš„ç½‘ç»œç¨³å®š
4. **ä¸­æ–­æ¢å¤**: å¯ä»¥ä½¿ç”¨Ctrl+Cå®‰å…¨ä¸­æ–­æµ‹è¯•

## ğŸ› ï¸ æ•…éšœæ’æŸ¥

### å¸¸è§é—®é¢˜
1. **"No prompts loaded"**: æ£€æŸ¥æ•°æ®é›†æ–‡ä»¶è·¯å¾„
2. **è¿æ¥å¤±è´¥**: ç¡®è®¤vLLMæœåŠ¡æ­£åœ¨è¿è¡Œ
3. **æ— æœåŠ¡ç«¯æŒ‡æ ‡**: æ£€æŸ¥OpenTelemetryå’ŒJaegeré…ç½®
4. **å†…å­˜ä¸è¶³**: å‡å°‘max_tokensæˆ–å¹¶å‘æ•°

### è°ƒè¯•æ¨¡å¼
```python
import logging
logging.basicConfig(level=logging.DEBUG)
# ç„¶åè¿è¡Œæµ‹è¯•è„šæœ¬
```
